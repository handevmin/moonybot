{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1b823d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import timedelta, datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import konlpy.tag\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "import csv\n",
    "\n",
    "\n",
    "# Configuration\n",
    "database_name = \"news_data.db\"\n",
    "table_name = \"main_news\"\n",
    "\n",
    "DATA_DIR = \"data/news_data/\"\n",
    "\n",
    "# Okt 형태소 분석기 사용\n",
    "Okt = konlpy.tag.Okt()\n",
    "\n",
    "# DB로부터 뉴스 크롤링데이터 가져오기\n",
    "def get_data():\n",
    "    try:\n",
    "        con = sqlite3.connect(DATA_DIR + database_name)\n",
    "        cursor = con.cursor()\n",
    "    except:\n",
    "        print(\"Connection failed!\")\n",
    "\n",
    "    try:\n",
    "        SQL = \"SELECT * from \" + table_name\n",
    "        df = pd.read_sql(SQL, con)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "    finally:\n",
    "        con.commit()\n",
    "        con.close()\n",
    "    return df\n",
    "\n",
    "######### 아래는 혹시 필요할까봐 각각의 과정을 함수화 한 내용입니다 ##########\n",
    "\n",
    "# 형태소 토큰화\n",
    "def word_tokenize(df):\n",
    "    # 형태소 분석 및 단어 추출\n",
    "    Okt = konlpy.tag.Okt()\n",
    "\n",
    "    stopwords = ['과', '도', '를', '으로', '자', '에', '와', '한', '하다', '의', '가', '이', '은', '들', '는', '좀', '잘', '수', '것', '만', '있고', '있어서', '있다는'] # 불용어 정의\n",
    "\n",
    "    df['contents'] = df['contents'].str.replace('[^가-힣A-Za-z0-9]+', ' ', regex=True) # 한글, 영문, 숫자를 제외한 특수문자, 따옴표 등은 정규표현식을 사용하여 모두 제거\n",
    "\n",
    "    print(df['contents'])\n",
    "\n",
    "    tokenized_data = []\n",
    "    for sentence in tqdm(df['contents'][:100]): # 일단 100개만\n",
    "        # word_tokens = Okt.pos(sentence, stem=False, norm=False)  # Okt 형태소 분석기를 이용한 토큰화\n",
    "        word_tokens =Okt.morphs(sentence, stem=True)\n",
    "        word_tokens = [word for word in word_tokens if not word in stopwords] # 불용어 제거\n",
    "        tokenized_data.append(word_tokens)\n",
    "\n",
    "    print(tokenized_data)\n",
    "\n",
    "    return tokenized_data\n",
    "\n",
    "# 정수 인코딩\n",
    "def integer_encoding(data):\n",
    "    print(type(data))\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(data)\n",
    "\n",
    "    # 단어 중요도 측정\n",
    "    threshold = 2\n",
    "    total_cnt = len(tokenizer.word_index)\n",
    "    rare_cnt = 0\n",
    "    total_freq = 0\n",
    "    rare_freq = 0\n",
    "\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        if(value<threshold):\n",
    "            rare_cnt = rare_cnt +1\n",
    "            rare_freq = rare_freq +value\n",
    "\n",
    "    print(\"단어 집합의 크기:\", total_cnt)\n",
    "    print(\"등장 빈도가 %s번 이하인 희귀 단어의 수: %s\" %(threshold-1, rare_cnt))\n",
    "    print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt/total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq/total_freq)*100)\n",
    "\n",
    "    vocab_size = total_cnt - rare_cnt + 1\n",
    "\n",
    "    tokenizer = Tokenizer(vocab_size)\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    encoded_data = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "    return encoded_data\n",
    "\n",
    "# 전체 기사의 길이 분포 확인\n",
    "def check_data_len(data):\n",
    "    print(\"뉴스기사의 최대 길이:\",max(len(news) for news in data))\n",
    "    print(\"뉴스기사의 평균 길이:\", sum(map(len, data))/len(data))\n",
    "    plt.hist([len(news) for news in data], bins=30)\n",
    "    plt.xlabel(\"length of samples\")\n",
    "    plt.ylabel(\"number of samples\")\n",
    "    plt.show()\n",
    "\n",
    "# 길이가 기준치 이하인 샘플의 비율 확인\n",
    "def check_percentage(data, threshold):\n",
    "    count = 0\n",
    "    for sentence in data:\n",
    "        if(len(sentence) <= threshold):\n",
    "            count +=1\n",
    "    print(\"전체 샘플 중 길이가 %s 이하인 데이터의 비율:%s\" %(threshold,(count/len(data))*100))\n",
    "\n",
    "def LSTM(padded_data):\n",
    "    embedding_dim = 100\n",
    "    hidden_units = 128\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(padded_data), embedding_dim))\n",
    "    model.add(LSTM(hidden_units))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode = 'min', verbose=1, patience =4)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor = 'val_acc', mode = 'max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "75f0422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>end</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_ratio</th>\n",
       "      <th>isup</th>\n",
       "      <th>avrage</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>transation_value</th>\n",
       "      <th>total_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>2409.41</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>2427.70</td>\n",
       "      <td>2432.37</td>\n",
       "      <td>2402.67</td>\n",
       "      <td>391599</td>\n",
       "      <td>7214620.0</td>\n",
       "      <td>1.900000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>2415.61</td>\n",
       "      <td>-56.44</td>\n",
       "      <td>-2.28</td>\n",
       "      <td>1</td>\n",
       "      <td>2443.00</td>\n",
       "      <td>2443.61</td>\n",
       "      <td>2415.61</td>\n",
       "      <td>580021</td>\n",
       "      <td>8452318.0</td>\n",
       "      <td>1.900000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>2472.05</td>\n",
       "      <td>21.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2433.47</td>\n",
       "      <td>2473.75</td>\n",
       "      <td>2426.14</td>\n",
       "      <td>436247</td>\n",
       "      <td>9562592.0</td>\n",
       "      <td>1.950000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>2450.93</td>\n",
       "      <td>24.04</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2441.21</td>\n",
       "      <td>2453.91</td>\n",
       "      <td>2433.48</td>\n",
       "      <td>336555</td>\n",
       "      <td>6826615.0</td>\n",
       "      <td>1.930000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>2426.89</td>\n",
       "      <td>-54.14</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>1</td>\n",
       "      <td>2432.06</td>\n",
       "      <td>2432.89</td>\n",
       "      <td>2417.01</td>\n",
       "      <td>448746</td>\n",
       "      <td>7891467.0</td>\n",
       "      <td>1.910000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      end  delta  delta_ratio  isup   avrage     high      low  \\\n",
       "0  2022-09-02  2409.41  -6.20        -0.26     1  2427.70  2432.37  2402.67   \n",
       "1  2022-09-01  2415.61 -56.44        -2.28     1  2443.00  2443.61  2415.61   \n",
       "2  2022-08-31  2472.05  21.12         0.86     0  2433.47  2473.75  2426.14   \n",
       "3  2022-08-30  2450.93  24.04         0.99     0  2441.21  2453.91  2433.48   \n",
       "4  2022-08-29  2426.89 -54.14        -2.18     1  2432.06  2432.89  2417.01   \n",
       "\n",
       "   volume  transation_value   total_value  \n",
       "0  391599         7214620.0  1.900000e+09  \n",
       "1  580021         8452318.0  1.900000e+09  \n",
       "2  436247         9562592.0  1.950000e+09  \n",
       "3  336555         6826615.0  1.930000e+09  \n",
       "4  448746         7891467.0  1.910000e+09  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "news_data = get_data()\n",
    "kospi_data = pd.read_csv(\"data/kospi_data/data_0601_20220904.csv\")\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aa5afc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>409</td>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>달러화 약세 월말효과로 유동성 호조</td>\n",
       "      <td>미래에셋증권, 주식형 펀드 자금유입 매수 여력 보강[프라임경제] 투신권에 월말 효과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>475</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>홈쇼핑·백화점 \"고맙다, 소비\"</td>\n",
       "      <td>[머니위크 전보규 기자][[머니위크]유통주, 내년에는 먹구름 걷힐까]유통주는 올해 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562</td>\n",
       "      <td>2011-02-10</td>\n",
       "      <td>이러다 2000선 밑으로?…패닉은 금물, 덜빠진 우등생주'정조준'</td>\n",
       "      <td>■트레이더에게 듣는다▷손은주 대우증권 광교지점 차장외국인 매도가 8000억에 육박했...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>608</td>\n",
       "      <td>2005-12-23</td>\n",
       "      <td>크리스마스엔 블루칩을 사세요</td>\n",
       "      <td>콜금리 잇단 인상에도 뭉칫돈 지속유입 대형 우량주 강세 예상[프라임경제] 황우석 쇼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>612</td>\n",
       "      <td>2011-02-16</td>\n",
       "      <td>당분간 위도 아래도 꽉막힌 장세로…박스권서 살아남으려면</td>\n",
       "      <td>■박옥희 IBK투자증권 스트래티지스트국내 증시의 모멘텀이 없는 가운데 어제에 이어 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id        date                                 title  \\\n",
       "0  409  2005-12-19                   달러화 약세 월말효과로 유동성 호조   \n",
       "1  475  2012-12-31                     홈쇼핑·백화점 \"고맙다, 소비\"   \n",
       "2  562  2011-02-10  이러다 2000선 밑으로?…패닉은 금물, 덜빠진 우등생주'정조준'   \n",
       "3  608  2005-12-23                       크리스마스엔 블루칩을 사세요   \n",
       "4  612  2011-02-16        당분간 위도 아래도 꽉막힌 장세로…박스권서 살아남으려면   \n",
       "\n",
       "                                            contents  \n",
       "0  미래에셋증권, 주식형 펀드 자금유입 매수 여력 보강[프라임경제] 투신권에 월말 효과...  \n",
       "1  [머니위크 전보규 기자][[머니위크]유통주, 내년에는 먹구름 걷힐까]유통주는 올해 ...  \n",
       "2  ■트레이더에게 듣는다▷손은주 대우증권 광교지점 차장외국인 매도가 8000억에 육박했...  \n",
       "3  콜금리 잇단 인상에도 뭉칫돈 지속유입 대형 우량주 강세 예상[프라임경제] 황우석 쇼...  \n",
       "4  ■박옥희 IBK투자증권 스트래티지스트국내 증시의 모멘텀이 없는 가운데 어제에 이어 ...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data['date'] = news_data['date'].apply(lambda x: str(x).split(' ')[0])  # 기존 date값에서 년-월-일만 저장\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "07e1859d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>end</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_ratio</th>\n",
       "      <th>isup</th>\n",
       "      <th>avrage</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>transation_value</th>\n",
       "      <th>total_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>409</td>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>달러화 약세 월말효과로 유동성 호조</td>\n",
       "      <td>미래에셋증권, 주식형 펀드 자금유입 매수 여력 보강[프라임경제] 투신권에 월말 효과...</td>\n",
       "      <td>1339.4</td>\n",
       "      <td>18.36</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1325.61</td>\n",
       "      <td>1339.48</td>\n",
       "      <td>1320.88</td>\n",
       "      <td>513998</td>\n",
       "      <td>4209738.0</td>\n",
       "      <td>633000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24779</td>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>‘황우석 쇼크’ 대안은 3박자 가치주</td>\n",
       "      <td>코스닥시장에서 바이오 테마주 등에 대한 조정세가 이어짐에 따라 ‘실적+배당+수급’의...</td>\n",
       "      <td>1339.4</td>\n",
       "      <td>18.36</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1325.61</td>\n",
       "      <td>1339.48</td>\n",
       "      <td>1320.88</td>\n",
       "      <td>513998</td>\n",
       "      <td>4209738.0</td>\n",
       "      <td>633000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24836</td>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>[11시40분 시황]주가 ‘黃쇼크’ 탈출 상승세</td>\n",
       "      <td>황우석 쇼크로 급락세를 보였던 서울증시에 반발 매수세가 유입되며 안정을 되찾고 있다...</td>\n",
       "      <td>1339.4</td>\n",
       "      <td>18.36</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1325.61</td>\n",
       "      <td>1339.48</td>\n",
       "      <td>1320.88</td>\n",
       "      <td>513998</td>\n",
       "      <td>4209738.0</td>\n",
       "      <td>633000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194946</td>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>[윤세욱의 마켓포인트]환율 불안…기간조정 가능성</td>\n",
       "      <td>시장은 이번주에도 조정을 이어갈 전망이다. 원/달러 환율이 1010원대로 하락함에 ...</td>\n",
       "      <td>1339.4</td>\n",
       "      <td>18.36</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1325.61</td>\n",
       "      <td>1339.48</td>\n",
       "      <td>1320.88</td>\n",
       "      <td>513998</td>\n",
       "      <td>4209738.0</td>\n",
       "      <td>633000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194952</td>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>개미들 투자규모 늘린다</td>\n",
       "      <td>직접투자계좌 최근 3개월여간 32만4000개 증가예탁금도 13조 돌파…“내년에도 증...</td>\n",
       "      <td>1339.4</td>\n",
       "      <td>18.36</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1325.61</td>\n",
       "      <td>1339.48</td>\n",
       "      <td>1320.88</td>\n",
       "      <td>513998</td>\n",
       "      <td>4209738.0</td>\n",
       "      <td>633000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        date                       title  \\\n",
       "0     409  2005-12-19         달러화 약세 월말효과로 유동성 호조   \n",
       "1   24779  2005-12-19        ‘황우석 쇼크’ 대안은 3박자 가치주   \n",
       "2   24836  2005-12-19  [11시40분 시황]주가 ‘黃쇼크’ 탈출 상승세   \n",
       "3  194946  2005-12-19  [윤세욱의 마켓포인트]환율 불안…기간조정 가능성   \n",
       "4  194952  2005-12-19                개미들 투자규모 늘린다   \n",
       "\n",
       "                                            contents     end  delta  \\\n",
       "0  미래에셋증권, 주식형 펀드 자금유입 매수 여력 보강[프라임경제] 투신권에 월말 효과...  1339.4  18.36   \n",
       "1  코스닥시장에서 바이오 테마주 등에 대한 조정세가 이어짐에 따라 ‘실적+배당+수급’의...  1339.4  18.36   \n",
       "2  황우석 쇼크로 급락세를 보였던 서울증시에 반발 매수세가 유입되며 안정을 되찾고 있다...  1339.4  18.36   \n",
       "3  시장은 이번주에도 조정을 이어갈 전망이다. 원/달러 환율이 1010원대로 하락함에 ...  1339.4  18.36   \n",
       "4  직접투자계좌 최근 3개월여간 32만4000개 증가예탁금도 13조 돌파…“내년에도 증...  1339.4  18.36   \n",
       "\n",
       "   delta_ratio  isup   avrage     high      low  volume  transation_value  \\\n",
       "0         1.39     0  1325.61  1339.48  1320.88  513998         4209738.0   \n",
       "1         1.39     0  1325.61  1339.48  1320.88  513998         4209738.0   \n",
       "2         1.39     0  1325.61  1339.48  1320.88  513998         4209738.0   \n",
       "3         1.39     0  1325.61  1339.48  1320.88  513998         4209738.0   \n",
       "4         1.39     0  1325.61  1339.48  1320.88  513998         4209738.0   \n",
       "\n",
       "   total_value  \n",
       "0  633000000.0  \n",
       "1  633000000.0  \n",
       "2  633000000.0  \n",
       "3  633000000.0  \n",
       "4  633000000.0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_data = pd.merge(news_data, kospi_data)\n",
    "#merge_data = merge_data[['contents','isup']] # 기사내용과 레이블 컬럼만 추출\n",
    "merge_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0af094c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65321    25일 아시아 주요 증시가 혼조 마감했다.일본 도쿄증시 닛케이225지수는 이날 전 ...\n",
       "71302    ⓒ게티이미지뱅크공매도 공시제도가 지난 30일 본격적으로 시행되면서 기관투자자들이 박...\n",
       "38877    [ 한민수 기자  ] 사진=게티이미지뱅크투자자들의 관심이 미국의 3월 연방공개시장위...\n",
       "27241    원/달러 환율 상승(원화 약세)으로 원/엔 환율에 민감한 가전, 디스플레이, 핸드셋...\n",
       "77966    [머니투데이 유윤정 기자]코스피가 닷새만에 반등하며 1640선을 회복했다. 코스피지...\n",
       "Name: contents, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = merge_data['contents'] # 기사내용과 컬럼 추출\n",
    "y = merge_data['isup'] # 레이블 컬럼 추출\n",
    "\n",
    "# 사이킷런을 이용하여 학습용 테스트와 테스트용 데이터를 분리\n",
    "train_data, test_data, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "\n",
    "# 데이터 갯수 5000개로 제한\n",
    "train_data = train_data[:5000]\n",
    "test_data = test_data[:5000]\n",
    "y_train = y_train[:5000]\n",
    "y_test = y_test[:5000]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5ecb52e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [17:13<00:00,  4.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [17:14<00:00,  4.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# 형태소 토큰화\n",
    "stopwords = ['과', '도', '를', '으로', '자', '에', '와', '한', '하다', '의', '가', '이', '은', '들', '는', '좀', '잘', '수', '것', '만', '있고', '있어서', '있다는'] # 불용어 정의\n",
    "\n",
    "train_data = train_data.str.replace('[^가-힣A-Za-z0-9]+', ' ', regex=True) # 한글, 영문, 숫자를 제외한 특수문자, 따옴표 등은 정규표현식을 사용하여 모두 제거\n",
    "test_data = test_data.str.replace('[^가-힣A-Za-z0-9]+', ' ', regex=True)\n",
    "\n",
    "X_train = []\n",
    "for sentence in tqdm(train_data):\n",
    "    # word_tokens = Okt.pos(sentence, stem=False, norm=False)  # Okt 형태소 분석기를 이용한 토큰화\n",
    "    word_tokens =Okt.morphs(sentence, stem=True)\n",
    "    word_tokens = [word for word in word_tokens if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(word_tokens)\n",
    "    \n",
    "X_test = []\n",
    "for sentence in tqdm(test_data):\n",
    "    # word_tokens = Okt.pos(sentence, stem=False, norm=False)  # Okt 형태소 분석기를 이용한 토큰화\n",
    "    word_tokens =Okt.morphs(sentence, stem=True)\n",
    "    word_tokens = [word for word in word_tokens if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(word_tokens)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f81d2a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기: 49703\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 26275\n",
      "단어 집합에서 희귀 단어의 비율: 52.86401223266202\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.3933562118204208\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# 단어 중요도 측정\n",
    "threshold = 3  # 등장빈도 임계값 (3회 미만)\n",
    "total_cnt = len(tokenizer.word_index) # 단어 수\n",
    "rare_cnt = 0  # 희귀 단어 수\n",
    "total_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    if(value<threshold):\n",
    "        rare_cnt = rare_cnt +1\n",
    "        rare_freq = rare_freq +value\n",
    "\n",
    "print(\"단어 집합의 크기:\", total_cnt)\n",
    "print(\"등장 빈도가 %s번 이하인 희귀 단어의 수: %s\" %(threshold-1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt/total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq/total_freq)*100)\n",
    "\n",
    "vocab_size = total_cnt - rare_cnt + 1  # 전체 단어 개수 중 빈도수 3회 미만인 단어는 제거\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(vocab_size) # 단어 집합의 크기를 케라스 토크나이저의 인자로 넘겨줌\n",
    "tokenizer.fit_on_texts(X_train)   # 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "65272bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# check_data_len(encoded_data)\n",
    "# check_percentage(encoded_data, 1000)\n",
    "\n",
    "# 데이터 패딩\n",
    "max_len = 1000\n",
    "X_train = pad_sequences(X_train , maxlen, padding='post') # 뒤에 0을 채워서 패딩\n",
    "X_test = pad_sequences(X_test , maxlen, padding='post')\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac5ac32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.5332 \n",
      "Epoch 1: val_acc improved from -inf to 0.52800, saving model to best_model.h5\n",
      "63/63 [==============================] - 1571s 24s/step - loss: 0.6916 - acc: 0.5332 - val_loss: 0.6919 - val_acc: 0.5280\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.5383  \n",
      "Epoch 2: val_acc did not improve from 0.52800\n",
      "63/63 [==============================] - 11135s 179s/step - loss: 0.6908 - acc: 0.5383 - val_loss: 0.6919 - val_acc: 0.5260\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6907 - acc: 0.5420\n",
      "Epoch 3: val_acc did not improve from 0.52800\n",
      "63/63 [==============================] - 384s 6s/step - loss: 0.6907 - acc: 0.5420 - val_loss: 0.6925 - val_acc: 0.5270\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.5322\n",
      "Epoch 4: val_acc did not improve from 0.52800\n",
      "63/63 [==============================] - 428s 7s/step - loss: 0.6931 - acc: 0.5322 - val_loss: 0.6936 - val_acc: 0.5280\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6905 - acc: 0.5425\n",
      "Epoch 5: val_acc did not improve from 0.52800\n",
      "63/63 [==============================] - 210s 3s/step - loss: 0.6905 - acc: 0.5425 - val_loss: 0.6921 - val_acc: 0.5270\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid')) # 활성화 함수로 시그모이드 사용\n",
    "\n",
    "# 정해진 에포크가 도달하지 못하였더라고 학습을 조기 종료(Early Stopping)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "# 검증 데이터의 정확도가 이전보다 좋아질 경우에만 모델을 저장\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) # 손실 함수로 크로스 엔트로피 함수를 사용\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "355486f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 46s 293ms/step - loss: 0.6901 - acc: 0.5414\n",
      "\n",
      " 테스트 정확도: 0.5414\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5') # 가장 정확도가 높은 모델이 저장된'best_model.h5'를 로드\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e39e27e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 532ms/step\n",
      "50.58% 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "    new_sentence = Okt.morphs(new_sentence, stem=True) # 토큰화\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "    score = float(loaded_model.predict(pad_new)) # 예측\n",
    "    if(score > 0.5):\n",
    "        print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "    else:\n",
    "        print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))\n",
    "\n",
    "today_news = \"(서울=뉴스1) 손엄지 기자 = 미국 연방준비제도(Fed, 연준)의 금리인상 속도 조절 기대감과 정부 유동성 공급 조치에 국내 증시가 상승마감했다. 24일 코스피는 전날 대비 23.04p(1.04%) 상승한 2236.16으로 장을 마쳤다. 외국인은 1498억원, 기관은 3246억원 각각 순매수했다. 개인은 4835억원 순매도했다. 선물시장에서 외국인은 662억원 순매도세를 기록했다. 김석환 미래에셋증권 연구원은 △미 연준의 금리인상 속도 조절 기대감 △일본의 외환시장 개입 △정부의 50조원 유동성 공급 조치 영향으로 증시가 상승했다고 분석했다.코스피 시가총액 상위 10개 종목 중 삼성SDI(3.67%), 삼성바이오로직스(3.07%), 삼성전자(2.86%), LG에너지솔루션(2.0%), SK하이닉스(1.44%), LG화학(1.23%), 삼성전자우(0.96%) 등은 상승했다. 기아(-3.83%), 현대차(-3.29%), NAVER(-1.2%) 등은 하락했다.상승 업종은 비금속광물(3.25%), 의료정밀(3.17%), 의약품(2.79%), 건설업(2.45%), 전기전자(2.43%) 등이다. 하락 업종은 운수장비(-1.83%), 보험(-0.97%), 금융업(-0.31%), 서비스업(-0.21%), 화학(-0.13%) 등이다.부동산 프로젝트 파이낸싱(PF) 관련 우려에도 금융당국의 유동성 공급 계획 발표에 건설업이 2% 넘게 올랐다.지난주 미국 뉴욕증시는 연준의 긴축 완화 기대감에 크게 상승했다. 21일(현지시간) 다우 지수는 전장 대비 748.97포인트(2.47%) 급등해 3만1082.56을 기록했고, 스탠다드앤푸어스(S&P)500은 86.97포인트(2.37%) 뛴 3752.75로 체결됐다. 나스닥 지수는 244.87포인트(2.31%) 올라 1만859.72로 거래를 마쳤다. 현재 나스닥100 지수선물은 0.26% 오름세다.코스닥은 전날 대비 14.02p(2.08%) 상승한 688.50를 가리키고 있다.외국인은 1128억원, 기관은 1987억원 각각 순매수했다. 개인은 3164억원 순매도했다.코스닥 시가총액 상위 10개 종목이 모두 올랐다. HLB(6.24%), 엘앤에프(3.88%), 리노공업(3.63%), 셀트리온헬스케어(2.82%), 셀트리온제약(2.37%), 펄어비스(1.86%), 천보(1.24%), 에코프로(0.88%), 에코프로비엠(0.56%), 카카오게임즈(0.53%) 등은 상승했다.상승 업종은 비금속(5.34%), 출판·매체복제(4.15%), 반도체(3.42%), 운송장비·부품(3.28%), 금속(2.84%) 등이다. 하락 업종은 통신서비스(-0.01%)다.서울외환시장에서 달러·원 환율은 전 거래일보다 0.1원 내린 1439.7원에 마감했다.장초반 달러 강세 압력 완화에 1429원까지 하락했지만, 엔화가 재차 변동성 확대되어 강세전환하고 위안화도 약세 기록한 영향에 하락폭을 반납했다.\"\n",
    "sentiment_predict(today_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b8138f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
